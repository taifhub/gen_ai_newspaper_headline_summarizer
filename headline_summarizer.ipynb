{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# News Headline Rewriter/Summarizer\n",
        "\n",
        "This notebook demonstrates the fine-tuned T5-small model for generating news headlines with LangChain integration for flexible prompting styles.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from transformers import T5Tokenizer, T5ForConditionalGeneration, pipeline\n",
        "# from langchain.llms import HuggingFacePipeline\n",
        "# from langchain.prompts import PromptTemplate\n",
        "# from langchain.chains import LLMChain\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# # Check device\n",
        "# device = 0 if torch.cuda.is_available() else -1\n",
        "# print(f\"Using device: {'CUDA' if device == 0 else 'CPU'}\")\n",
        "\n",
        "\n",
        "# WORKING CODE:\n",
        "from transformers import pipeline\n",
        "from langchain_community.llms import HuggingFacePipeline  # community namespace\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Fine-tuned Model\n",
        "\n",
        "Load the T5-small model that was fine-tuned in `train_model.ipynb`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path to fine-tuned model\n",
        "model_path = \"./models/t5-small-headlines-final\"\n",
        "\n",
        "# Load model and tokenizer\n",
        "print(\"Loading fine-tuned model...\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "\n",
        "# Create summarization pipeline\n",
        "summarization_pipeline = pipeline(\n",
        "    \"summarization\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    max_length=128,\n",
        "    min_length=10,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9\n",
        ")\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Basic Headline Generation\n",
        "\n",
        "Test the model with basic summarization before adding LangChain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_headline(article_text, max_length=128, num_beams=4):\n",
        "    \"\"\"Generate a headline from an article using the fine-tuned model.\"\"\"\n",
        "    result = summarization_pipeline(\n",
        "        article_text,\n",
        "        max_length=max_length,\n",
        "        num_beams=num_beams,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    return result[0]['summary_text']\n",
        "\n",
        "# Test with a sample article\n",
        "sample_article = \"\"\"\n",
        "Breaking news from Washington: The Senate has passed a landmark climate bill \n",
        "that aims to reduce carbon emissions by 40% over the next decade. The bill, \n",
        "which received bipartisan support, includes significant investments in renewable \n",
        "energy infrastructure and tax incentives for green technology companies. \n",
        "Environmental groups have praised the legislation as a major step forward in \n",
        "combating climate change, while some industry leaders express concerns about \n",
        "the economic impact of the new regulations.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Sample Article:\")\n",
        "print(sample_article)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\\nGenerated Headline:\")\n",
        "headline = generate_headline(sample_article)\n",
        "print(headline)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. LangChain Integration\n",
        "\n",
        "Integrate LangChain to enable flexible prompting styles like \"make it more exciting\" or \"make it more formal\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wrap the summarization pipeline in LangChain\n",
        "llm = HuggingFacePipeline(pipeline=summarization_pipeline)\n",
        "\n",
        "print(\"LangChain integration ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create Different Headline Styles\n",
        "\n",
        "Define functions to generate headlines in different styles using creative temperature and sampling parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HeadlineStyler:\n",
        "    \"\"\"Generate headlines in different styles.\"\"\"\n",
        "    \n",
        "    def __init__(self, model, tokenizer, device):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "    \n",
        "    def _generate(self, text, temperature=0.7, top_p=0.9, max_length=64):\n",
        "        \"\"\"Internal generation method with custom parameters.\"\"\"\n",
        "        pipe = pipeline(\n",
        "            \"summarization\",\n",
        "            model=self.model,\n",
        "            tokenizer=self.tokenizer,\n",
        "            device=self.device,\n",
        "            max_length=max_length,\n",
        "            min_length=5,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            num_return_sequences=1\n",
        "        )\n",
        "        result = pipe(text)\n",
        "        return result[0]['summary_text']\n",
        "    \n",
        "    def exciting(self, article):\n",
        "        \"\"\"Generate an exciting, attention-grabbing headline.\"\"\"\n",
        "        # Higher temperature for more creative/exciting outputs\n",
        "        return self._generate(article, temperature=0.9, top_p=0.95, max_length=64)\n",
        "    \n",
        "    def formal(self, article):\n",
        "        \"\"\"Generate a formal, professional headline.\"\"\"\n",
        "        # Lower temperature for more conservative outputs\n",
        "        return self._generate(article, temperature=0.5, top_p=0.8, max_length=64)\n",
        "    \n",
        "    def short(self, article):\n",
        "        \"\"\"Generate a short, concise headline.\"\"\"\n",
        "        # Shorter max length\n",
        "        return self._generate(article, temperature=0.7, top_p=0.9, max_length=32)\n",
        "    \n",
        "    def detailed(self, article):\n",
        "        \"\"\"Generate a longer, more detailed headline.\"\"\"\n",
        "        # Longer max length\n",
        "        return self._generate(article, temperature=0.7, top_p=0.9, max_length=128)\n",
        "    \n",
        "    def neutral(self, article):\n",
        "        \"\"\"Generate a balanced, neutral headline.\"\"\"\n",
        "        # Balanced parameters\n",
        "        return self._generate(article, temperature=0.7, top_p=0.9, max_length=64)\n",
        "\n",
        "# Initialize the styler\n",
        "styler = HeadlineStyler(model, tokenizer, device)\n",
        "print(\"Headline Styler initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Demo: Different Headline Styles\n",
        "\n",
        "Let's test the different styles on various news articles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def demo_styles(article, title=\"News Article\"):\n",
        "    \"\"\"Demonstrate all headline styles for a given article.\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"  {title}\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "    print(\"Original Article:\")\n",
        "    print(article[:300] + \"...\" if len(article) > 300 else article)\n",
        "    print(f\"\\n{'-'*80}\\n\")\n",
        "    \n",
        "    print(\"üéØ NEUTRAL HEADLINE:\")\n",
        "    print(f\"   {styler.neutral(article)}\\n\")\n",
        "    \n",
        "    print(\"üöÄ EXCITING HEADLINE:\")\n",
        "    print(f\"   {styler.exciting(article)}\\n\")\n",
        "    \n",
        "    print(\"üì∞ FORMAL HEADLINE:\")\n",
        "    print(f\"   {styler.formal(article)}\\n\")\n",
        "    \n",
        "    print(\"‚ö° SHORT HEADLINE:\")\n",
        "    print(f\"   {styler.short(article)}\\n\")\n",
        "    \n",
        "    print(\"üìù DETAILED HEADLINE:\")\n",
        "    print(f\"   {styler.detailed(article)}\\n\")\n",
        "\n",
        "# Test Article 1: Technology\n",
        "tech_article = \"\"\"\n",
        "Apple Inc. announced today the launch of its latest iPhone model, featuring \n",
        "revolutionary AI capabilities and a groundbreaking camera system. The new device \n",
        "includes an advanced neural engine that can process complex machine learning tasks \n",
        "directly on the phone, eliminating the need for cloud processing. Industry analysts \n",
        "predict the new iPhone will set sales records, with pre-orders already exceeding \n",
        "expectations. The starting price is set at $999, with premium models reaching $1,499.\n",
        "\"\"\"\n",
        "\n",
        "demo_styles(tech_article, \"Technology News\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Article 2: Sports\n",
        "sports_article = \"\"\"\n",
        "In a stunning upset at the championship finals, the underdog team defeated the \n",
        "reigning champions 3-2 in overtime. The rookie player scored the winning goal \n",
        "in the final seconds, sending fans into a frenzy. This marks the first championship \n",
        "victory for the franchise in over 50 years. The coach credited the team's dedication \n",
        "and training regimen for their success. Celebrations erupted in the city as thousands \n",
        "of fans took to the streets to celebrate the historic win.\n",
        "\"\"\"\n",
        "\n",
        "demo_styles(sports_article, \"Sports News\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Article 3: Science\n",
        "science_article = \"\"\"\n",
        "Researchers at MIT have developed a new material that can change its properties \n",
        "in response to temperature, potentially revolutionizing construction and manufacturing. \n",
        "The material, which combines polymers with nanoscale structures, can become rigid \n",
        "or flexible depending on environmental conditions. Scientists believe this breakthrough \n",
        "could lead to self-healing buildings and adaptive clothing. The research, published \n",
        "in Nature Materials, has attracted significant interest from major technology companies \n",
        "looking to commercialize the discovery.\n",
        "\"\"\"\n",
        "\n",
        "demo_styles(science_article, \"Science News\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Interactive Headline Generator\n",
        "\n",
        "Create your own headlines by entering custom articles below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_custom_headline(article_text, style=\"neutral\"):\n",
        "    \"\"\"\n",
        "    Generate a headline with a specific style.\n",
        "    \n",
        "    Args:\n",
        "        article_text: The news article text\n",
        "        style: One of 'neutral', 'exciting', 'formal', 'short', 'detailed'\n",
        "    \"\"\"\n",
        "    style_map = {\n",
        "        'neutral': styler.neutral,\n",
        "        'exciting': styler.exciting,\n",
        "        'formal': styler.formal,\n",
        "        'short': styler.short,\n",
        "        'detailed': styler.detailed\n",
        "    }\n",
        "    \n",
        "    if style not in style_map:\n",
        "        print(f\"Unknown style: {style}. Using 'neutral' instead.\")\n",
        "        style = 'neutral'\n",
        "    \n",
        "    return style_map[style](article_text)\n",
        "\n",
        "# Example usage\n",
        "print(\"Interactive Headline Generator Ready!\")\n",
        "print(\"\\nAvailable styles: neutral, exciting, formal, short, detailed\")\n",
        "print(\"\\nExample:\")\n",
        "custom_article = \"\"\"\n",
        "The local city council approved a new public park project that will transform \n",
        "an abandoned industrial site into a green space with playgrounds, walking trails, \n",
        "and a community garden. The project is expected to be completed within two years \n",
        "and will cost $5 million, funded through a combination of city budget and private donations.\n",
        "\"\"\"\n",
        "\n",
        "print(f\"\\nArticle: {custom_article[:200]}...\")\n",
        "print(f\"\\nExciting Style: {generate_custom_headline(custom_article, 'exciting')}\")\n",
        "print(f\"Formal Style: {generate_custom_headline(custom_article, 'formal')}\")\n",
        "print(f\"Short Style: {generate_custom_headline(custom_article, 'short')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Comparison with Pre-trained Model\n",
        "\n",
        "Let's compare our fine-tuned model with the original T5-small to see the improvement.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load original T5-small for comparison\n",
        "print(\"Loading original T5-small model for comparison...\")\n",
        "original_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "original_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "original_pipeline = pipeline(\n",
        "    \"summarization\",\n",
        "    model=original_model,\n",
        "    tokenizer=original_tokenizer,\n",
        "    device=device,\n",
        "    max_length=128,\n",
        "    min_length=10\n",
        ")\n",
        "\n",
        "def compare_models(article):\n",
        "    \"\"\"Compare headlines from original and fine-tuned models.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Article:\", article[:200] + \"...\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "    \n",
        "    original_result = original_pipeline(article, do_sample=False)\n",
        "    finetuned_result = generate_headline(article)\n",
        "    \n",
        "    print(\"üìò ORIGINAL T5-SMALL:\")\n",
        "    print(f\"   {original_result[0]['summary_text']}\\n\")\n",
        "    \n",
        "    print(\"‚ú® FINE-TUNED MODEL:\")\n",
        "    print(f\"   {finetuned_result}\\n\")\n",
        "\n",
        "# Test comparison\n",
        "comparison_article = \"\"\"\n",
        "A major earthquake measuring 7.2 on the Richter scale struck the coastal region \n",
        "early this morning, causing widespread damage and triggering tsunami warnings. \n",
        "Emergency services are responding to multiple collapsed buildings, and authorities \n",
        "have evacuated thousands of residents from low-lying areas. The government has \n",
        "declared a state of emergency and called for international assistance.\n",
        "\"\"\"\n",
        "\n",
        "compare_models(comparison_article)\n",
        "\n",
        "print(\"\\n\" + \"üí° Note: The fine-tuned model should produce more news-like headlines \"\n",
        "      \"specifically tailored to the CNN/DailyMail dataset style.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrates:\n",
        "1. ‚úÖ Loading a fine-tuned T5-small model for news headline generation\n",
        "2. ‚úÖ Basic headline generation from news articles  \n",
        "3. ‚úÖ LangChain integration with HuggingFace pipelines\n",
        "4. ‚úÖ Multiple headline styles (exciting, formal, short, detailed, neutral)\n",
        "5. ‚úÖ Interactive headline generation\n",
        "6. ‚úÖ Comparison with the base T5-small model\n",
        "\n",
        "### Key Features:\n",
        "- **Flexible Prompting**: Different styles through temperature and sampling parameters\n",
        "- **Local Execution**: No API keys required, runs entirely on local hardware\n",
        "- **Practical NLP**: Real-world application of fine-tuning for summarization\n",
        "- **Manageable Scale**: Simple project suitable for learning and demonstration\n",
        "\n",
        "### Next Steps:\n",
        "- Experiment with different temperature values for various tones\n",
        "- Try fine-tuning on domain-specific news (sports, tech, etc.)\n",
        "- Add more sophisticated prompt engineering with LangChain\n",
        "- Deploy as a web service using Flask or Streamlit\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
